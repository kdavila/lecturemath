
# ========================================================
#  Input/Output Path
# ========================================================

# Main video database file
VIDEO_DATABASE_PATH = lecture_data/db_LectureMath.xml
VIDEO_FILES_PATH = lecture_data/videos

# Main output root
OUTPUT_PATH = lecture_data/output

VIDEO_BASED_ANNOTATIONS = 0

# Video Export
FRAME_EXPORT_FPS = 6.0
OUTPUT_FRAME_EXPORT = lecture_data/LectureMath_VOC/
OUTPUT_FRAME_EXPORT_FORMAT = jpg
OUTPUT_FRAME_EXPORT_QUALITY = 25


# ========================================
#  Binarization using FCN 
# ========================================

FCN_BINARIZER_USE_CUDA = True

FCN_BINARIZER_SAVE_BINARY = True
FCN_BINARIZER_SAVE_BINARY_PATH = lecture_data/output/images

# Pre-Training

# ... pretrain by reconstruction .... 
FCN_BINARIZER_PRETRAIN_REC_IMAGES_DIR = lecture_data/pretrain_rec_dataset/train_images
FCN_BINARIZER_PRETRAIN_REC_DEBUG_DIR = lecture_data/pretrain_rec_dataset/debug_images
FCN_BINARIZER_PRETRAIN_REC_DEBUG_SAVE = 1
FCN_BINARIZER_PRETRAIN_REC_DEBUG_PREFIX = images/PRETRAIN_FCN_REC_

FCN_BINARIZER_PRETRAIN_REC_LEARNING_RATE = 0.01
FCN_BINARIZER_PRETRAIN_REC_EPOCHS = 100

FCN_BINARIZER_PRETRAIN_REC_MEDIAN = True
FCN_BINARIZER_PRETRAIN_REC_MEDIAN_BLUR_K = 35


# ... pretrain by text detection .... 
# ICDAR 2019 ArT 
FCN_BINARIZER_PRETRAIN_IMAGES_DIR = lecture_data/pretrain_text_dataset/train_images
FCN_BINARIZER_PRETRAIN_MASKS_DIR = lecture_data/pretrain_text_dataset/train_binary_masks
FCN_BINARIZER_PRETRAIN_EVAL_IMAGES_DIR = lecture_data/pretrain_text_dataset/train_images
FCN_BINARIZER_PRETRAIN_EVAL_MASKS_DIR = lecture_data/pretrain_text_dataset/train_binary_masks

FCN_BINARIZER_PRETRAIN_USE_RECONSTRUCTION_OUTPUT = True
FCN_BINARIZER_PRETRAIN_RECONSTRUCTION_OUTPUT = models/LectureNet_PRETRAINED_REC.dat
FCN_BINARIZER_PRETRAIN_TEXT_OUTPUT = models/LectureNet_PRETRAINED_TEXT.dat
FCN_BINARIZER_PRETRAIN_TEXT_DEBUG_SAVE = 1
FCN_BINARIZER_PRETRAIN_TEXT_DEBUG_DIR = lecture_data/pretrain_rec_dataset/debug_images
FCN_BINARIZER_PRETRAIN_TEXT_DEBUG_PREFIX = images/PRETRAIN_FCN_TEXT_

FCN_BINARIZER_PRETRAIN_EVAL_BIN_TRESHOLD = 128 


FCN_BINARIZER_PRETRAIN_PRELOAD_IMAGES = False

FCN_BINARIZER_PRETRAIN_BATCH_SIZE = 8
FCN_BINARIZER_PRETRAIN_LEARNING_RATE = 0.01
FCN_BINARIZER_PRETRAIN_EPOCHS = 100

# Data Augmentation (some apply to both training and pretraining)
FCN_BINARIZER_TRAIN_CROP_SIZE = (256, 256)
FCN_BINARIZER_TRAIN_CROP_REMOVE_EMPTY_BORDERS = True
FCN_BINARIZER_TRAIN_CROP_MIN_FOREGROUND = 0.1

FCN_BINARIZER_TRAIN_CROP_FLIP_CHANCE = 0.5

FCN_BINARIZER_TRAIN_COLOR_INVERT_CHANGE = 0.50

FCN_BINARIZER_TRAIN_LUMINOSITY_CHANGE_CHANCE = 0.125

FCN_BINARIZER_TRAIN_COLOR_CHANGE_CHANCE = 0.10
FCN_BINARIZER_TRAIN_GAUSSIAN_NOISE_CHANCE = 0.20
FCN_BINARIZER_TRAIN_GAUSSIAN_NOISE_LEVEL = 5.0

# Text mask and weights 
FCN_BINARIZER_TRAIN_WEIGHT_EXPANSION = 1
# FCN_BINARIZER_TRAIN_WEIGHT_FOREGROUND_PROPORTION = 0.5
FCN_BINARIZER_TRAIN_WEIGHT_FOREGROUND_EXTRA = 1.0

FCN_BINARIZER_TRAIN_TEXT_MASK_EXPANSION = 15

# Training Parameters
FCN_BINARIZER_TRAIN_USE_PRETRAIN_OUTPUT = True
FCN_BINARIZER_TRAIN_FROM_RECONSTRUCTION_PRETRAIN = False
FCN_BINARIZER_TRAIN_PRETRAIN_OUTPUT = models/LectureNet_PRETRAINED_TEXT.dat

FCN_BINARIZER_TRAIN_OUTPUT = models/LectureNet_model_BIN.dat

FCN_BINARIZER_TRAIN_DEBUG_SAVE = 1
FCN_BINARIZER_TRAIN_DEBUG_DIR = lecture_data/train_bin_debug
FCN_BINARIZER_TRAIN_DEBUG_PREFIX = images/DEBUG_BIN_


FCN_BINARIZER_TRAIN_BATCH_SIZE = 8
FCN_BINARIZER_TRAIN_LEARNING_RATE = 0.001
FCN_BINARIZER_TRAIN_EPOCHS = 200
FCN_BINARIZER_TRAIN_BG_CLASS_WEIGHT = None

# Architecture parameters
FCN_BINARIZER_NET_DOWN_CONV_FILTERS_1 = 48
FCN_BINARIZER_NET_DOWN_CONV_FILTERS_2 = 96
FCN_BINARIZER_NET_DOWN_CONV_FILTERS_3 = 192
FCN_BINARIZER_NET_DOWN_CONV_FILTERS_4 = 384
FCN_BINARIZER_NET_DOWN_CONV_FILTERS_5 = 768

FCN_BINARIZER_NET_MIDDLE_CONV_FILTERS_MIDDLE = 768

FCN_BINARIZER_NET_UPSAMPLE_FILTERS_5 = 384
FCN_BINARIZER_NET_UP_CONV_FILTERS_5 = 384
FCN_BINARIZER_NET_UPSAMPLE_FILTERS_4 = 192
FCN_BINARIZER_NET_UP_CONV_FILTERS_4 = 192
FCN_BINARIZER_NET_UPSAMPLE_FILTERS_3 = 96
FCN_BINARIZER_NET_UP_CONV_FILTERS_3 = 96
FCN_BINARIZER_NET_UPSAMPLE_FILTERS_2 = 48
FCN_BINARIZER_NET_UP_CONV_FILTERS_2 = 48
FCN_BINARIZER_NET_UPSAMPLE_FILTERS_1 = 32
FCN_BINARIZER_NET_UP_CONV_FILTERS_1 = 32

FCN_BINARIZER_NET_PIXEL_FEATURES_1 = 32
FCN_BINARIZER_NET_PIXEL_FEATURES_2 = 16
FCN_BINARIZER_NET_PIXEL_KERNEL_SIZE = 7

FCN_BINARIZER_NET_KERNEL_SIZE = 3


# =====================================================
#   Binarization using ML Binarizer or LectureNet
# =====================================================

BINARIZATION_OUTPUT = tempo_binary_

BINARIZATION_DEBUG_MODE = True
# output binary images until this length of video (in milliseconds)
BINARIZATION_DEBUG_END_TIME = 50000

BINARIZATION_USE_FCN_BINARIZER = True
BINARIZATION_FCN_LECTURENET_DIR = models
BINARIZATION_FCN_LECTURENET_FILENAME = LectureNet_model_BIN.dat


# ===========================================
#   Connected Components Stability Analysis
# ===========================================

CC_STABILITY_OUTPUT = tempo_stability_
CC_RECONSTRUCTED_OUTPUT = tempo_bin_reconstructed_
CC_CONFLICTS_OUTPUT = tempo_cc_conflicts_
CC_ST3D_OUTPUT = tempo_cc_ST3D_

CC_STABILITY_MIN_RECALL = 0.850
CC_STABILITY_MIN_PRECISION = 0.850
CC_STABILITY_MAX_GAP = 85
CC_STABILITY_MIN_TIMES = 3

CC_GROUPING_MIN_IMAGE_THRESHOLD = 0.5
CC_GROUPING_TEMPORAL_WINDOW = 5
CC_GROUPING_MIN_RECALL = 0.5
CC_GROUPING_MIN_TIME_F_MEASURE = None
CC_GROUPING_MIN_TIME_IOU = None


# ===========================================
#   Temporal Segmentation of the Video 
# ===========================================

VIDEO_SEGMENTATION_OUTPUT = tempo_intervals_

# 1 - Sums
# 2 - Conflicts
# 3 - Del Events (from CC Groups)
VIDEO_SEGMENTATION_METHOD = 3  

VIDEO_SEGMENTATION_SUM_MIN_SEGMENT = 10
VIDEO_SEGMENTATION_SUM_MIN_ERASE_RATIO = 0.05

# 0 - None 
# 3 - CC Area Union
# 4 - CC Area Intersection
# 5 - CC Area IOU
VIDEO_SEGMENTATION_CONFLICTS_WEIGHTS = 3

# 0 - None 
# 1 - matched pixels
# 2 - unmatched pixels
# 3 - IOU: 1 - (matched / (matched + unmatched))
VIDEO_SEGMENTATION_CONFLICTS_WEIGHTS_PIXELS = 3


# Manners of weighting by time 
# 0 - Constant
# 1 - Weight by the length of the gap
# 2 - Weight by the normalized length of elements in conflict
VIDEO_SEGMENTATION_CONFLICTS_WEIGHTS_TIME = 1

# minimum conflicst to accept split
VIDEO_SEGMENTATION_CONFLICTS_MIN_CONFLICTS = 0.03
# minimum segment length to consider splitting it (original = 50)
VIDEO_SEGMENTATION_CONFLICTS_MIN_SPLIT = 20
# minimum segment length to accept split. (original = 25)
# 5
VIDEO_SEGMENTATION_CONFLICTS_MIN_LENGTH = 15

# ========================================
#  Deleted CC Video Segmentation
# ========================================

VIDEO_SEGMENTATION_DEL_EVENT_MIN_LENGTH = 3
# 0.00005
VIDEO_SEGMENTATION_DEL_EVENT_ADD_THRESHOLD = 0.00005

VIDEO_SEGMENTATION_DEL_EVENT_THRESHOLD = 0.0008

# ========================================
#     Summary Generation
# ========================================

SUMMARY_KEYFRAMES_OUTPUT = tempo_segments_


# ========================================
#   Shared parameters
# ========================================
SAMPLING_FPS = 1.0
